{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:21.315782Z",
     "start_time": "2019-09-03T10:04:19.553866Z"
    }
   },
   "outputs": [],
   "source": [
    "%install-location $cwd/swift-install\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:29.117747Z",
     "start_time": "2019-09-03T10:04:21.317793Z"
    }
   },
   "outputs": [],
   "source": [
    "import Foundation\n",
    "import TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:30.455111Z",
     "start_time": "2019-09-03T10:04:29.122514Z"
    }
   },
   "outputs": [],
   "source": [
    "import Python\n",
    "let gym = Python.import(\"gym\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:30.528757Z",
     "start_time": "2019-09-03T10:04:30.458059Z"
    }
   },
   "outputs": [],
   "source": [
    "public typealias TF = Tensor<Float32>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:30.682010Z",
     "start_time": "2019-09-03T10:04:30.530801Z"
    }
   },
   "outputs": [],
   "source": [
    "struct StateRecord {\n",
    "    public var state: TF\n",
    "}\n",
    "\n",
    "\n",
    "struct Observation {\n",
    "    public let obs: Int\n",
    "}\n",
    "\n",
    "\n",
    "struct Action {\n",
    "    public let action: Int\n",
    "}\n",
    "\n",
    "struct Reward{\n",
    "    public let reward: Float\n",
    "}\n",
    "\n",
    "struct StateActionPair : Hashable {\n",
    "    public var state: Observation\n",
    "    public var act: Action\n",
    "    \n",
    "    static func == (lhs: StateActionPair, rhs: StateActionPair) -> Bool {\n",
    "        return (lhs.state.obs == rhs.state.obs) && (lhs.act.action == rhs.act.action)\n",
    "    }\n",
    "    \n",
    "    func hash(into hasher: inout Hasher) {\n",
    "        hasher.combine(state.obs)\n",
    "        hasher.combine(act.action)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:30.747856Z",
     "start_time": "2019-09-03T10:04:30.683682Z"
    }
   },
   "outputs": [],
   "source": [
    "public typealias SA = Dictionary<StateActionPair, Float>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:30.812050Z",
     "start_time": "2019-09-03T10:04:30.749497Z"
    }
   },
   "outputs": [],
   "source": [
    "var stateDict : SA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:31.021375Z",
     "start_time": "2019-09-03T10:04:30.816715Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "func select_greedy_action(s: SA, \n",
    "                          obs: Observation) -> Action {\n",
    "    \n",
    "    let (_, a) = best_action_value(s:s, cs:obs)\n",
    "    \n",
    "    return a\n",
    "}\n",
    "\n",
    "func best_action_value(s: SA, \n",
    "                       cs: Observation) -> (Reward, Action)\n",
    "{\n",
    "    var best_value: Float = 0\n",
    "    var best_action = Action(action:0)\n",
    "    let r : Range = 0..<4\n",
    "    for i in r {\n",
    "        var a = Action(action:i)\n",
    "        var pair  = StateActionPair(state: cs, act:a) \n",
    "        if ( (s[pair] ?? 0) > best_value) {\n",
    "            best_value = s[pair] ?? 0\n",
    "            best_action = a\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return (Reward(reward:best_value), \n",
    "            best_action)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:31.099507Z",
     "start_time": "2019-09-03T10:04:31.024829Z"
    }
   },
   "outputs": [],
   "source": [
    "let random = Python.import(\"numpy.random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:31.351925Z",
     "start_time": "2019-09-03T10:04:31.102296Z"
    }
   },
   "outputs": [],
   "source": [
    "func select_eps_greedy_action(s: SA, \n",
    "                              obs: Observation, \n",
    "                              n_actions: Int, \n",
    "                              eps: Float) -> Action {\n",
    "    \n",
    "    let (val, act) = best_action_value(s:s, cs: obs)\n",
    "    \n",
    "    let r = Float( random.random() )!\n",
    "    \n",
    "    if (r < eps) {\n",
    "        let r_act = Int(random.randint(0, n_actions))!\n",
    "        return Action(action: r_act)\n",
    "        \n",
    "    } else {\n",
    "        return act\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:31.679207Z",
     "start_time": "2019-09-03T10:04:31.353730Z"
    }
   },
   "outputs": [],
   "source": [
    "func q_learning(sr:inout SA, current_obs: Observation, \n",
    "                next_obs: Observation, r: Reward, a: Action, \n",
    "                g: Float, lr: Float) -> SA\n",
    "{\n",
    "    let (best_value, _) = best_action_value(s:sr, \n",
    "                                             cs: next_obs)\n",
    "    \n",
    "    let Q_target = r.reward + g * best_value.reward\n",
    "    let pair = StateActionPair(state: current_obs, act:a)\n",
    "    let Q_error = Q_target - (sr[pair] ?? 0)\n",
    "    \n",
    "    \n",
    "    sr[pair] = (sr[pair] ?? 0) + lr * Q_error\n",
    "    \n",
    "    return sr\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:31.816074Z",
     "start_time": "2019-09-03T10:04:31.681025Z"
    }
   },
   "outputs": [],
   "source": [
    "func step_env(env: PythonObject, act: Action) -> \n",
    "                    (Observation, \n",
    "                     Reward, \n",
    "                     Bool) {\n",
    "    let res = env.step(act.action)\n",
    "    let obs = Int(res[0])!\n",
    "    let rew = Float(res[1])!\n",
    "    let done = Bool(res[2])!\n",
    "                        \n",
    "    return (Observation(obs: obs), \n",
    "            Reward(reward: rew),\n",
    "            done)\n",
    "    \n",
    "}\n",
    "func reset_env(env: PythonObject) -> Observation {\n",
    "    \n",
    "    let o = Int( env.reset() )!\n",
    "    return Observation(obs: o)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:32.051911Z",
     "start_time": "2019-09-03T10:04:31.817874Z"
    }
   },
   "outputs": [],
   "source": [
    "func test_game(env: PythonObject, s: SA, \n",
    "                no_games: Int ) -> Reward\n",
    "{\n",
    "    var reward_games : [Float] = []\n",
    "    var rewards : Float = 0.0\n",
    "    let myRange: Range = 0..<no_games\n",
    "    \n",
    "    for i in myRange {\n",
    "        var obs = reset_env(env: env)\n",
    "        var next_obs : Observation\n",
    "        var reward : Reward\n",
    "        \n",
    "        var done = false\n",
    "        while (!done) {\n",
    "            var next_act = select_greedy_action(s: s, obs: obs)\n",
    "            \n",
    "            (obs, reward, done) = step_env(env:env, act:next_act )\n",
    "            \n",
    "            rewards += reward.reward\n",
    "            \n",
    "            if (done) {\n",
    "                reward_games.append(rewards)\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    }\n",
    "    \n",
    "    return Reward(reward:(rewards/Float(no_games)))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:32.127550Z",
     "start_time": "2019-09-03T10:04:32.053596Z"
    }
   },
   "outputs": [],
   "source": [
    "let Gamma : Float = 0.95\n",
    "\n",
    "var epsilon: Float = 1.0\n",
    "let EPS_DECAY_RATE : Float = 0.99939\n",
    "let LEARNING_RATE : Float = 0.8\n",
    "\n",
    "let TEST_EPISODES = 100\n",
    "let MAX_GAMES = 150001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:34.348798Z",
     "start_time": "2019-09-03T10:04:32.129509Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let env = gym.make(\"FrozenLake-v0\")\n",
    "let o = Int(env.reset())!\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:34.469596Z",
     "start_time": "2019-09-03T10:04:34.351587Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\r\n",
      "4\r\n"
     ]
    }
   ],
   "source": [
    "let obs_length: Int = Int(env.observation_space.n)!\n",
    "let n_actions: Int = Int(env.action_space.n)!\n",
    "print(obs_length)\n",
    "print(n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:36.536306Z",
     "start_time": "2019-09-03T10:04:34.471831Z"
    }
   },
   "outputs": [],
   "source": [
    "var state_matrix = TF(zeros: [obs_length, n_actions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:36.621154Z",
     "start_time": "2019-09-03T10:04:36.539461Z"
    }
   },
   "outputs": [],
   "source": [
    "// STill need to initialise the dictionary!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:36.799024Z",
     "start_time": "2019-09-03T10:04:36.622951Z"
    }
   },
   "outputs": [],
   "source": [
    "var games_count = 0\n",
    "var test_rewards_list : [Reward] = []\n",
    "\n",
    "var obs = Observation(obs:o)\n",
    "var sr : SA = [StateActionPair(state:Observation(obs: 0), act:Action(action:0)) : 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:05:08.091555Z",
     "start_time": "2019-09-03T10:04:36.801994Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Games count: 0 Epsilon: 0.99939\n",
      "0.0\n",
      "Games count: 1000 Epsilon: 0.54292196\n",
      "0.08\n",
      "Games count: 2000 Epsilon: 0.29494384\n",
      "0.63\n",
      "Games count: 3000 Epsilon: 0.16022928\n",
      "0.58\n",
      "Games count: 4000 Epsilon: 0.0870451\n",
      "0.38\n",
      "Games count: 5000 Epsilon: 0.04728754\n",
      "0.56\n",
      "Games count: 6000 Epsilon: 0.025689088\n",
      "0.62\n",
      "Games count: 7000 Epsilon: 0.013955676\n",
      "0.73\n",
      "Games count: 8000 Epsilon: 0.0075814645\n",
      "0.73\n",
      "Games count: 9000 Epsilon: 0.004118649\n",
      "0.72\n",
      "Games count: 10000 Epsilon: 0.0022374657\n",
      "0.69\n",
      "Games count: 11000 Epsilon: 0.0012155101\n",
      "0.5\n",
      "Games count: 12000 Epsilon: 0.0006603301\n",
      "0.73\n",
      "Games count: 13000 Epsilon: 0.0003587266\n",
      "0.67\n",
      "Games count: 14000 Epsilon: 0.00019487953\n",
      "0.75\n",
      "Games count: 15000 Epsilon: 0.000105869\n",
      "0.78\n",
      "Games count: 16000 Epsilon: 5.751362e-05\n",
      "0.68\n",
      "Games count: 17000 Epsilon: 3.1244417e-05\n",
      "0.74\n",
      "Games count: 18000 Epsilon: 1.6973609e-05\n",
      "0.81\n",
      "Games count: 19000 Epsilon: 9.220952e-06\n",
      "0.66\n",
      "Games count: 20000 Epsilon: 5.0093154e-06\n",
      "0.71\n",
      "Games count: 21000 Epsilon: 2.7213264e-06\n",
      "0.72\n",
      "Games count: 22000 Epsilon: 1.47837e-06\n",
      "0.72\n",
      "Games count: 23000 Epsilon: 8.031285e-07\n",
      "0.74\n",
      "Games count: 24000 Epsilon: 4.3630214e-07\n",
      "0.73\n",
      "Games count: 25000 Epsilon: 2.370225e-07\n",
      "0.81\n",
      "Games count: 26000 Epsilon: 1.2876322e-07\n",
      "0.73\n",
      "Games count: 27000 Epsilon: 6.995102e-08\n",
      "0.69\n",
      "Games count: 28000 Epsilon: 3.8001097e-08\n",
      "0.78\n",
      "Games count: 29000 Epsilon: 2.0644208e-08\n",
      "0.72\n",
      "Games count: 30000 Epsilon: 1.12150245e-08\n",
      "0.71\n",
      "Games count: 31000 Epsilon: 6.0925993e-09\n",
      "0.74\n",
      "Games count: 32000 Epsilon: 3.3098264e-09\n",
      "0.79\n",
      "Games count: 33000 Epsilon: 1.7980738e-09\n",
      "0.8\n",
      "Games count: 34000 Epsilon: 9.768086e-10\n",
      "0.78\n",
      "Games count: 35000 Epsilon: 5.3065397e-10\n",
      "0.78\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "Current stack trace:",
      "\tframe #31: 0x00007f433fe0f3cb $__lldb_expr82`step_env(env=<unavailable>, act=(action = 0)) at <Cell 12>:5:15",
      "\tframe #32: 0x00007f433012e1ce $__lldb_expr136`main at <Cell 20>:12:36"
     ]
    }
   ],
   "source": [
    "games_count = 0\n",
    "epsilon = 1.0\n",
    "\n",
    "var total_reward : Float = 0\n",
    "\n",
    "while (games_count < MAX_GAMES) {\n",
    "    let act = select_eps_greedy_action(s: sr, obs:obs, \n",
    "                                       n_actions:n_actions,\n",
    "                                       eps: epsilon\n",
    "                                      )\n",
    "    \n",
    "    let (next_obs, reward, done) = step_env(env: env, act:act)\n",
    "    sr = q_learning(sr: &sr, current_obs: obs, next_obs:next_obs, \n",
    "                   r: reward, a: act, g: Gamma,\n",
    "                   lr: LEARNING_RATE)\n",
    "    obs = next_obs\n",
    "    total_reward += reward.reward\n",
    "    //print(total_reward)\n",
    "    if (done) {\n",
    "        epsilon *= EPS_DECAY_RATE\n",
    "    \n",
    "        if ((games_count % 1000) == 0) {\n",
    "            let test_reward = test_game(env: env, s: sr, no_games: TEST_EPISODES)\n",
    "            test_rewards_list.append(test_reward)\n",
    "            print(\"Games count: \" + String(games_count) + \" Epsilon: \" + String(epsilon))\n",
    "            print(test_reward.reward)\n",
    "        }\n",
    "        \n",
    "        // do testing logic... \n",
    "        obs = reset_env(env: env)\n",
    "        games_count+=1\n",
    "        total_reward=0\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:05:15.363265Z",
     "start_time": "2019-09-03T10:05:15.111720Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "â–¿ Reward\n",
       "  - reward : 0.75\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_game(env: env, s: sr, no_games: TEST_EPISODES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
