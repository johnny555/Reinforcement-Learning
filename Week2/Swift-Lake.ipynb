{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:13.030884Z",
     "start_time": "2019-09-03T10:04:10.934220Z"
    }
   },
   "outputs": [],
   "source": [
    "%install-location $cwd/swift-install\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:21.735417Z",
     "start_time": "2019-09-03T10:04:13.032863Z"
    }
   },
   "outputs": [],
   "source": [
    "import Foundation\n",
    "import TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:23.195704Z",
     "start_time": "2019-09-03T10:04:21.737202Z"
    }
   },
   "outputs": [],
   "source": [
    "import Python\n",
    "let gym = Python.import(\"gym\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:23.273095Z",
     "start_time": "2019-09-03T10:04:23.198432Z"
    }
   },
   "outputs": [],
   "source": [
    "public typealias TF = Tensor<Float32>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:23.423117Z",
     "start_time": "2019-09-03T10:04:23.274649Z"
    }
   },
   "outputs": [],
   "source": [
    "struct StateRecord {\n",
    "    public var state: TF\n",
    "}\n",
    "\n",
    "\n",
    "struct Observation {\n",
    "    public let obs: Int\n",
    "}\n",
    "\n",
    "\n",
    "struct Action {\n",
    "    public let action: Int\n",
    "}\n",
    "\n",
    "struct Reward{\n",
    "    public let reward: Float\n",
    "}\n",
    "\n",
    "struct StateRewardPair : Hashable {\n",
    "    public var state: Observation\n",
    "    public var act: Action\n",
    "    \n",
    "    static func == (lhs: StateRewardPair, rhs: StateRewardPair) -> Bool {\n",
    "        return (lhs.state.obs == rhs.state.obs) && (lhs.act.action == rhs.act.action)\n",
    "    }\n",
    "    \n",
    "    func hash(into hasher: inout Hasher) {\n",
    "        hasher.combine(state.obs)\n",
    "        hasher.combine(act.action)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:24.847795Z",
     "start_time": "2019-09-03T10:04:23.425894Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "func select_greedy_action(s: StateRecord, \n",
    "                          obs: Observation) -> Action {\n",
    "    let (_, a) = best_action_value(s:s, cs:obs)\n",
    "    \n",
    "    return a\n",
    "}\n",
    "\n",
    "func best_action_value(s: StateRecord, \n",
    "                       cs: Observation) -> (Reward, Action)\n",
    "{\n",
    "    \n",
    "    let q_row = s.state[cs.obs]\n",
    "\n",
    "    let max_value = Float(q_row.max().scalars[0])\n",
    "    let best_action = Int(q_row.argmax().scalars[0])\n",
    "    \n",
    "    return (Reward(reward:max_value), Action(action:best_action))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:27.493942Z",
     "start_time": "2019-09-03T10:04:24.849415Z"
    }
   },
   "outputs": [],
   "source": [
    "var a = TF(zeros: [10,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:28.964012Z",
     "start_time": "2019-09-03T10:04:27.499760Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0]\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:30.549071Z",
     "start_time": "2019-09-03T10:04:28.967684Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor<Int32>\n",
      "Float\n"
     ]
    }
   ],
   "source": [
    "print(type(of:a[3].argmax()))\n",
    "print(type(of: a[0][0].scalars[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:30.625233Z",
     "start_time": "2019-09-03T10:04:30.550994Z"
    }
   },
   "outputs": [],
   "source": [
    "let random = Python.import(\"numpy.random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:30.847093Z",
     "start_time": "2019-09-03T10:04:30.627662Z"
    }
   },
   "outputs": [],
   "source": [
    "func select_eps_greedy_action(s: StateRecord, \n",
    "                              obs: Observation, \n",
    "                              n_actions: Int, \n",
    "                              eps: Float) -> Action {\n",
    "    \n",
    "    let (val, act) = best_action_value(s:s, cs: obs)\n",
    "    \n",
    "    let r = Float(  random.random() )!\n",
    "    \n",
    "    if (r < eps) {\n",
    "        let r_act = Int(random.randint(0, n_actions))!\n",
    "        return Action(action: r_act)\n",
    "        \n",
    "    } else {\n",
    "        return act\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:32.301828Z",
     "start_time": "2019-09-03T10:04:30.849343Z"
    }
   },
   "outputs": [],
   "source": [
    "func q_learning(sr: StateRecord, current_obs: Observation, \n",
    "                next_obs: Observation, r: Reward, a: Action, \n",
    "                g: Float, lr: Float) -> StateRecord\n",
    "{\n",
    "    let (best_value, _) = best_action_value(s:sr, \n",
    "                                             cs: next_obs)\n",
    "    \n",
    "    let Q_target = r.reward + g * best_value.reward\n",
    "    let Q_error = Q_target - sr.state[current_obs.obs, a.action]\n",
    "    \n",
    "    var new_state = StateRecord(state: sr.state)\n",
    "    \n",
    "    new_state.state[current_obs.obs, a.action] += lr * Q_error\n",
    "    \n",
    "    return new_state\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:32.457098Z",
     "start_time": "2019-09-03T10:04:32.304870Z"
    }
   },
   "outputs": [],
   "source": [
    "func step_env(env: PythonObject, act: Action) -> \n",
    "                    (Observation, \n",
    "                     Reward, \n",
    "                     Bool) {\n",
    "    let res = env.step(act.action)\n",
    "    let obs = Int(res[0])!\n",
    "    let rew = Float(res[1])!\n",
    "    let done = Bool(res[2])!\n",
    "                        \n",
    "    return (Observation(obs: obs), \n",
    "            Reward(reward: rew),\n",
    "            done)\n",
    "    \n",
    "}\n",
    "func reset_env(env: PythonObject) -> Observation {\n",
    "    \n",
    "    let o = Int( env.reset() )!\n",
    "    return Observation(obs: o)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:32.728709Z",
     "start_time": "2019-09-03T10:04:32.460240Z"
    }
   },
   "outputs": [],
   "source": [
    "func test_game(env: PythonObject, s: StateRecord, \n",
    "                no_games: Int ) -> Reward\n",
    "{\n",
    "    var reward_games : [Float] = []\n",
    "    var rewards : Float = 0.0\n",
    "    let myRange: Range = 0..<no_games\n",
    "    \n",
    "    for i in myRange {\n",
    "        var obs = reset_env(env: env)\n",
    "        var next_obs : Observation\n",
    "        var reward : Reward\n",
    "        \n",
    "        var done = false\n",
    "        while (!done) {\n",
    "            var next_act = select_greedy_action(s: s, obs: obs)\n",
    "            \n",
    "            (obs, reward, done) = step_env(env:env, act:next_act )\n",
    "            \n",
    "            rewards += reward.reward\n",
    "            \n",
    "            if (done) {\n",
    "                reward_games.append(rewards)\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    }\n",
    "    \n",
    "    return Reward(reward:(rewards/Float(no_games)))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:32.805614Z",
     "start_time": "2019-09-03T10:04:32.731615Z"
    }
   },
   "outputs": [],
   "source": [
    "let Gamma : Float = 0.95\n",
    "\n",
    "var epsilon: Float = 1.0\n",
    "let EPS_DECAY_RATE : Float = 0.99939\n",
    "let LEARNING_RATE : Float = 0.8\n",
    "\n",
    "let TEST_EPISODES = 100\n",
    "let MAX_GAMES = 15001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:35.184690Z",
     "start_time": "2019-09-03T10:04:32.808429Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let env = gym.make(\"FrozenLake-v0\")\n",
    "let o = Int(env.reset())!\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:35.360353Z",
     "start_time": "2019-09-03T10:04:35.187778Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\r\n",
      "4\r\n"
     ]
    }
   ],
   "source": [
    "let obs_length: Int = Int(env.observation_space.n)!\n",
    "let n_actions: Int = Int(env.action_space.n)!\n",
    "print(obs_length)\n",
    "print(n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:36.483826Z",
     "start_time": "2019-09-03T10:04:35.363139Z"
    }
   },
   "outputs": [],
   "source": [
    "var state_matrix = TF(zeros: [obs_length, n_actions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:36.635666Z",
     "start_time": "2019-09-03T10:04:36.485770Z"
    }
   },
   "outputs": [],
   "source": [
    "var games_count = 0\n",
    "var test_rewards_list : [Reward] = []\n",
    "\n",
    "var obs = Observation(obs:o)\n",
    "var sr = StateRecord(state:state_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:11:38.987244Z",
     "start_time": "2019-09-03T10:04:52.399821Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Games count: 0 Epsilon: 0.99939\n",
      "0.0\n",
      "Games count: 1000 Epsilon: 0.54292196\n",
      "0.5\n",
      "Games count: 2000 Epsilon: 0.29494384\n",
      "0.49\n",
      "Games count: 3000 Epsilon: 0.16022928\n",
      "0.16\n",
      "Games count: 4000 Epsilon: 0.0870451\n",
      "0.28\n",
      "Games count: 5000 Epsilon: 0.04728754\n",
      "0.66\n",
      "Games count: 6000 Epsilon: 0.025689088\n",
      "0.59\n",
      "Games count: 7000 Epsilon: 0.013955676\n",
      "0.61\n",
      "Games count: 8000 Epsilon: 0.0075814645\n",
      "0.78\n",
      "Games count: 9000 Epsilon: 0.004118649\n",
      "0.78\n",
      "Games count: 10000 Epsilon: 0.0022374657\n",
      "0.63\n",
      "Games count: 11000 Epsilon: 0.0012155101\n",
      "0.51\n",
      "Games count: 12000 Epsilon: 0.0006603301\n",
      "0.59\n",
      "Games count: 13000 Epsilon: 0.0003587266\n",
      "0.75\n",
      "Games count: 14000 Epsilon: 0.00019487953\n",
      "0.69\n",
      "Games count: 15000 Epsilon: 0.000105869\n",
      "0.41\n"
     ]
    }
   ],
   "source": [
    "games_count = 0\n",
    "epsilon = 1.0\n",
    "\n",
    "var total_reward : Float = 0\n",
    "\n",
    "while (games_count < MAX_GAMES) {\n",
    "    let act = select_eps_greedy_action(s: sr, obs:obs, \n",
    "                                       n_actions:n_actions,\n",
    "                                       eps: epsilon\n",
    "                                      )\n",
    "    \n",
    "    let (next_obs, reward, done) = step_env(env: env, act:act)\n",
    "    sr = q_learning(sr: sr, current_obs: obs, next_obs:next_obs, \n",
    "                   r: reward, a: act, g: Gamma,\n",
    "                   lr: LEARNING_RATE)\n",
    "    obs = next_obs\n",
    "    total_reward += reward.reward\n",
    "    //print(total_reward)\n",
    "    if (done) {\n",
    "        epsilon *= EPS_DECAY_RATE\n",
    "    \n",
    "        if ((games_count % 1000) == 0) {\n",
    "            let test_reward = test_game(env: env, s: sr, no_games: TEST_EPISODES)\n",
    "            test_rewards_list.append(test_reward)\n",
    "            print(\"Games count: \" + String(games_count) + \" Epsilon: \" + String(epsilon))\n",
    "            print(test_reward.reward)\n",
    "        }\n",
    "        \n",
    "        // do testing logic... \n",
    "        obs = reset_env(env: env)\n",
    "        games_count+=1\n",
    "        total_reward=0\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:36.698651Z",
     "start_time": "2019-09-03T10:04:11.004Z"
    }
   },
   "outputs": [],
   "source": [
    "sr.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:36.699650Z",
     "start_time": "2019-09-03T10:04:11.005Z"
    }
   },
   "outputs": [],
   "source": [
    "let myRange: Range = 0..<16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:36.700523Z",
     "start_time": "2019-09-03T10:04:11.008Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in myRange {\n",
    "    print(sr.state[i].argmax())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:36.701463Z",
     "start_time": "2019-09-03T10:04:11.010Z"
    }
   },
   "outputs": [],
   "source": [
    "sr.state[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:36.702393Z",
     "start_time": "2019-09-03T10:04:11.012Z"
    }
   },
   "outputs": [],
   "source": [
    "env.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T10:04:36.703469Z",
     "start_time": "2019-09-03T10:04:11.014Z"
    }
   },
   "outputs": [],
   "source": [
    "test_game(env: env, s: sr, no_games: TEST_EPISODES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
